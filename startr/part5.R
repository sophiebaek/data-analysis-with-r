# 머신러닝의 정의: 컴퓨터가 명시적으로 프로그램되지 않고도 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 연구 분야
# result = f(data)

# 머신러닝의 종류:
# 1. 정답의 유무에 따른 구분
  # 1-1. 지도학습 (Supervised Learning): ex) 학습 분류, 회귀 모델
  # 1-2. 비지도학습 (Unsupervised Learning): ex) 군집화, 연관규칙분석 -> y가 없음
# 2. 학습 목적에 따른 구분
  # 2-1. 분류: ex) 로지스틱 회귀 분석, 나이브 베이즈, 의사결정나무, 인공 신경망, SVM -> 종속변수가 명목형 (categorical) 변수
  # 2-2. 회귀 (Regression): ex) 선형 회귀 분석, 인공신경망, SVR -> 종속변수가 연속형 (continuous) 변수
  # 2-3. 군집화 (Clustering): ex) K-Means 군집화, 계층적 군집화 -> 유사한 개체들의 집단을 판별
  # 2-4. 연관규칙분석 (Association Rule): -> 연관성이 높은 아이템들로 구성된 규칙 집합을 생성하는 방법론 / 추천시스템에 주로 사용 / 장바구니 분석이라고 불리기도 함

# 머신러닝 기반 추천 알고리즘:
# - User 기반 추천: 사용자와 비슷한 성향의 사용자들이 기존에 좋아했던 항목을 추천하는 방법
# - Item 기반 추천: 사용자가 기존에 좋아했던 항목과 유사한 특성을 지닌 항목을 추천하는 방법

##############################################################################

# 확률 용어:
# 확률 실험: 실험 결과를 미리 알 수 없지만, 발생 가능한 모든 결과는 알려져 있는 실험
# 표본 공간 (Sample space): 가능한 모든 결과들의 집합
# 사건 (Event): 표본 공간의 부분 집합
# 확률: 특정 사건이 발생할 가능성을 확률이라고 하며, 사건 E가 발생할 확률은 P(E)로 표기함

# 확률의 공리:
# 표본공간 S의 각 사건 E에 대하여 사건 E가 발생할 확률 P(E)는 아래 세 조건을 만족해야 함
# 1. 0 <= P(E) <= 1
# 2. P(S) = 1
# 3. 각 사건들이 서로 배반사건 (교집합이 없는 경우)일 때, 각 이벤트의 합집합의 확률 = 각 이벤트의 확률의 합

# 조건부 확률: 특정 사건 B가 발생했다는 가정 하에 사건 A가 발생할 확률을 조건부 확률이라고 하며, 사건 B에 대한 사건 A의 조건부 확률은 P(A|B)로 표기함

# 확률 변수: 표본 공간을 실수 값에 대응시키는 함수를 확률 변수라고 하며, 주로 X로 표기함
# - 이산 확률 변수: 확률 변수가 가지는 값을 셀 수 있는 경우
# - 연속 확률 변수: 확률 변수가 가지는 값을 셀 수 없는 경우

# 확률 분포: 확률 변수를 확률 값에 대응시키는 함수를 확률 분포라고 하며, 주로 f로 표기함
# - 확률 질량 함수: 이산 확률 변수의 확률 분포
# - 확률 밀도 함수: 연속 확률 변수의 확률 분포
